{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "casual-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "conventional-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's start by loading our data\n",
    "\n",
    "# Starting with the labels\n",
    "with open(\"./data/processed_training_labels.csv\") as labels_file:\n",
    "    labels_string = labels_file.read()\n",
    "    labels = np.array(labels_string.split(','), dtype=int)\n",
    "    \n",
    "# Recall we had 60000 images. Let's make sure we didn't lose anythin\n",
    "assert len(labels) == 60000\n",
    "\n",
    "# Now for the images\n",
    "images = []\n",
    "with open(\"./data/processed_training_images\") as images_file:\n",
    "    raw_image_strings = images_file.readlines()\n",
    "    for img_string in raw_image_strings:\n",
    "        img_flat = np.array(img_string.split(\",\"), dtype=np.double)\n",
    "        img = np.reshape(img_flat, (28,28))\n",
    "        images.append(img)\n",
    "        \n",
    "# Again, let's do some random spot checking to make sure everything is as we expect\n",
    "assert len(images) == 60000\n",
    "i1,i2,i3 = np.random.randint(0, 60000, 3)\n",
    "assert images[i1].shape == (28,28)\n",
    "assert images[i2].shape == (28,28)\n",
    "assert images[i3].shape == (28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "previous-drill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f49a875ba00>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And again, we'll just print out some images and their labels for good measure \n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.add_subplot(1,4,1)\n",
    "plt.text(9,40,f\"label: {labels[i1]}\")\n",
    "plt.imshow(images[i1], cmap='gray')\n",
    "fig.add_subplot(1,4,2)\n",
    "plt.text(10,40,f\"label: {labels[i2]}\")\n",
    "plt.imshow(images[i2], cmap='gray')\n",
    "fig.add_subplot(1,4,3)\n",
    "plt.text(11,40,f\"label: {labels[i3]}\")\n",
    "plt.imshow(images[i3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "perfect-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Okay! Now the fun begins.\n",
    "# To start, let's just get everything over to Torch\n",
    "train_labels = torch.tensor(labels).to('cuda:0')\n",
    "train_images = torch.tensor(images).to('cuda:0')\n",
    "\n",
    "# Let's convert them to the shape we need\n",
    "t_images = train_images.reshape((60000,1,784)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "egyptian-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 10])\n",
      "torch.Size([60000, 1, 784])\n"
     ]
    }
   ],
   "source": [
    "# And we can take a look at their shapes\n",
    "print(t_labels.shape)\n",
    "print(t_images.shape)\n",
    "len(t_images)\n",
    "t_labels = torch.zeros(60000, 10).to('cuda:0')\n",
    "for i, l in enumerate(labels):\n",
    "    t_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "pregnant-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: !DF! Try just one fully connected layer\n",
    "# TODO: !DF! Write explanation on MSELoss()\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1,1,3)\n",
    "        self.fc1 = nn.Linear(782, 80)\n",
    "        self.fc2 = nn.Linear(80, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "elegant-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.to('cuda:0')\n",
    "#net = net.float()\n",
    "USE_GPU = True\n",
    "\n",
    "#if USE_GPU:\n",
    "    ##device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #t_labels = t_labels.to(device)\n",
    "    #t_images = t_images.to(device)\n",
    "    #net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "comprehensive-education",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, running_loss: 210.3797607421875\n",
      "Epoch: 0, Batch: 2000, running_loss: 1343.5395960435271\n",
      "Epoch: 0, Batch: 4000, running_loss: 45.325023271143436\n",
      "Epoch: 0, Batch: 6000, running_loss: 45.015405997633934\n",
      "Epoch: 0, Batch: 8000, running_loss: 45.01344175636768\n",
      "Epoch: 0, Batch: 10000, running_loss: 44.98749636858702\n",
      "Epoch: 0, Batch: 12000, running_loss: 45.01728831976652\n",
      "Epoch: 0, Batch: 14000, running_loss: 45.00252152979374\n",
      "Epoch: 0, Batch: 16000, running_loss: 45.00426197052002\n",
      "Epoch: 0, Batch: 18000, running_loss: 44.97360632568598\n",
      "Epoch: 0, Batch: 20000, running_loss: 45.014309741556644\n",
      "Epoch: 0, Batch: 22000, running_loss: 45.000772409141064\n",
      "Epoch: 0, Batch: 24000, running_loss: 45.01628389954567\n",
      "Epoch: 0, Batch: 26000, running_loss: 44.985598266124725\n",
      "Epoch: 0, Batch: 28000, running_loss: 45.01908699423075\n",
      "Epoch: 0, Batch: 30000, running_loss: 45.0136511400342\n",
      "Epoch: 0, Batch: 32000, running_loss: 44.989374935626984\n",
      "Epoch: 0, Batch: 34000, running_loss: 45.008496306836605\n",
      "Epoch: 0, Batch: 36000, running_loss: 45.00405541062355\n",
      "Epoch: 0, Batch: 38000, running_loss: 45.01843950152397\n",
      "Epoch: 0, Batch: 40000, running_loss: 45.008714854717255\n",
      "Epoch: 0, Batch: 42000, running_loss: 44.99181903898716\n",
      "Epoch: 0, Batch: 44000, running_loss: 45.00970969349146\n",
      "Epoch: 0, Batch: 46000, running_loss: 45.01111374050379\n",
      "Epoch: 0, Batch: 48000, running_loss: 44.9945307970047\n",
      "Epoch: 0, Batch: 50000, running_loss: 45.018803618848324\n",
      "Epoch: 0, Batch: 52000, running_loss: 45.019784435629845\n",
      "Epoch: 0, Batch: 54000, running_loss: 45.01218655705452\n",
      "Epoch: 0, Batch: 56000, running_loss: 45.01629124581814\n",
      "Epoch: 0, Batch: 58000, running_loss: 44.99394927173853\n",
      "Epoch: 1, Batch: 0, running_loss: 0.09032981842756271\n",
      "Epoch: 1, Batch: 2000, running_loss: 44.99874974787235\n",
      "Epoch: 1, Batch: 4000, running_loss: 45.00272745639086\n",
      "Epoch: 1, Batch: 6000, running_loss: 44.98876775056124\n",
      "Epoch: 1, Batch: 8000, running_loss: 45.00879634171724\n",
      "Epoch: 1, Batch: 10000, running_loss: 44.988258831202984\n",
      "Epoch: 1, Batch: 12000, running_loss: 45.01634958386421\n",
      "Epoch: 1, Batch: 14000, running_loss: 45.00269826501608\n",
      "Epoch: 1, Batch: 16000, running_loss: 45.004225350916386\n",
      "Epoch: 1, Batch: 18000, running_loss: 44.97358237206936\n",
      "Epoch: 1, Batch: 20000, running_loss: 45.014299154281616\n",
      "Epoch: 1, Batch: 22000, running_loss: 45.00076495856047\n",
      "Epoch: 1, Batch: 24000, running_loss: 45.01627679169178\n",
      "Epoch: 1, Batch: 26000, running_loss: 44.98559109121561\n",
      "Epoch: 1, Batch: 28000, running_loss: 45.01907815039158\n",
      "Epoch: 1, Batch: 30000, running_loss: 45.01364408433437\n",
      "Epoch: 1, Batch: 32000, running_loss: 44.98936865478754\n",
      "Epoch: 1, Batch: 34000, running_loss: 45.008486457169056\n",
      "Epoch: 1, Batch: 36000, running_loss: 45.00404696166515\n",
      "Epoch: 1, Batch: 38000, running_loss: 45.01843159645796\n",
      "Epoch: 1, Batch: 40000, running_loss: 45.00870629400015\n",
      "Epoch: 1, Batch: 42000, running_loss: 44.9918108433485\n",
      "Epoch: 1, Batch: 44000, running_loss: 45.00970268249512\n",
      "Epoch: 1, Batch: 46000, running_loss: 45.0111076310277\n",
      "Epoch: 1, Batch: 48000, running_loss: 44.99452459812164\n",
      "Epoch: 1, Batch: 50000, running_loss: 45.018795013427734\n",
      "Epoch: 1, Batch: 52000, running_loss: 45.01977576315403\n",
      "Epoch: 1, Batch: 54000, running_loss: 45.01217748224735\n",
      "Epoch: 1, Batch: 56000, running_loss: 45.01628091931343\n",
      "Epoch: 1, Batch: 58000, running_loss: 44.9939421415329\n",
      "Epoch: 2, Batch: 0, running_loss: 0.09032978862524033\n",
      "Epoch: 2, Batch: 2000, running_loss: 44.99874211847782\n",
      "Epoch: 2, Batch: 4000, running_loss: 45.00271903723478\n",
      "Epoch: 2, Batch: 6000, running_loss: 44.98875877261162\n",
      "Epoch: 2, Batch: 8000, running_loss: 45.00879009068012\n",
      "Epoch: 2, Batch: 10000, running_loss: 44.98824883252382\n",
      "Epoch: 2, Batch: 12000, running_loss: 45.01634196192026\n",
      "Epoch: 2, Batch: 14000, running_loss: 45.002689868211746\n",
      "Epoch: 2, Batch: 16000, running_loss: 45.00421575456858\n",
      "Epoch: 2, Batch: 18000, running_loss: 44.97357629239559\n",
      "Epoch: 2, Batch: 20000, running_loss: 45.014293894171715\n",
      "Epoch: 2, Batch: 22000, running_loss: 45.000756181776524\n",
      "Epoch: 2, Batch: 24000, running_loss: 45.01627069711685\n",
      "Epoch: 2, Batch: 26000, running_loss: 44.98558371514082\n",
      "Epoch: 2, Batch: 28000, running_loss: 45.01906926929951\n",
      "Epoch: 2, Batch: 30000, running_loss: 45.0136371999979\n",
      "Epoch: 2, Batch: 32000, running_loss: 44.98936191946268\n",
      "Epoch: 2, Batch: 34000, running_loss: 45.0084764957428\n",
      "Epoch: 2, Batch: 36000, running_loss: 45.004038885235786\n",
      "Epoch: 2, Batch: 38000, running_loss: 45.01842375099659\n",
      "Epoch: 2, Batch: 40000, running_loss: 45.008697994053364\n",
      "Epoch: 2, Batch: 42000, running_loss: 44.991802394390106\n",
      "Epoch: 2, Batch: 44000, running_loss: 45.00969538092613\n",
      "Epoch: 2, Batch: 46000, running_loss: 45.01110188663006\n",
      "Epoch: 2, Batch: 48000, running_loss: 44.99451844394207\n",
      "Epoch: 2, Batch: 50000, running_loss: 45.018786042928696\n",
      "Epoch: 2, Batch: 52000, running_loss: 45.01976698637009\n",
      "Epoch: 2, Batch: 54000, running_loss: 45.01216860860586\n",
      "Epoch: 2, Batch: 56000, running_loss: 45.016271129250526\n",
      "Epoch: 2, Batch: 58000, running_loss: 44.9939349219203\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss().to('cuda:0')\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    for i in range(0,len(t_images), 4):\n",
    "        #raw_batch = t_images[i:i+4]\n",
    "        #batch = torch.zeros(4,1,784).to('cuda:0')\n",
    "        #for j, img in enumerate(raw_batch):\n",
    "            #batch[j] = img.flatten().double()\n",
    "        #batch_labels = t_labels[i:i+4]\n",
    "        #targets = torch.zeros(len(batch_labels),10).to('cuda:0')\n",
    "        #for k,t in enumerate(targets):\n",
    "            #label = batch_labels[k]\n",
    "            #t[label] = 1\n",
    "        \n",
    "        #batch = batch.to(device)\n",
    "        #targets = targets.to(device)\n",
    "        net.zero_grad()\n",
    "        out = net(t_images[i:i+4])\n",
    "        loss = criterion(out, t_labels[i:i+4])\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 0:\n",
    "            ## I recommend doing things like this. It helped me catch mistakes\n",
    "            #print(batch[0][0])\n",
    "            #plt.imshow(batch[0][0].reshape((28,28)), cmap='gray')\n",
    "            #plt.show()\n",
    "            #print(targets[0])\n",
    "            print(f\"Epoch: {epoch}, Batch: {i}, running_loss: {running_loss}\")\n",
    "            running_loss = 0.0\n",
    "        for f in net.parameters():\n",
    "            f.data.sub_(f.grad.data * 0.01)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(t_images[2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "surgical-layout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(net(t_images[2].flatten().float().unsqueeze(0).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sweet-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/processed_testing_labels.csv\") as labels_file:\n",
    "    labels_string = labels_file.read()\n",
    "    testing_labels = np.array(labels_string.split(','), dtype=int)\n",
    "    \n",
    "# Recall we had 60000 images. Let's make sure we didn't lose anythin\n",
    "assert len(testing_labels) == 10000\n",
    "\n",
    "# Now for the images\n",
    "testing_images = []\n",
    "with open(\"./data/processed_testing_images\") as images_file:\n",
    "    raw_image_strings = images_file.readlines()\n",
    "    for img_string in raw_image_strings:\n",
    "        img_flat = np.array(img_string.split(\",\"), dtype=np.double)\n",
    "        img = np.reshape(img_flat, (28,28))\n",
    "        testing_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "exotic-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_labels = torch.tensor(testing_labels).to('cuda:0')\n",
    "t_test_images = torch.tensor(testing_images).to('cuda:0')\n",
    "t_test_images = t_test_images.reshape(10000, 784).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "optical-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8291 / 10000\n"
     ]
    }
   ],
   "source": [
    "correct = []\n",
    "for i,img in enumerate(t_test_images):\n",
    "    res = torch.argmax(net(img.unsqueeze(0).unsqueeze(0)))\n",
    "    targ = t_test_labels[i]\n",
    "    if res == targ:\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        correct.append(0)\n",
    "\n",
    "print(f\"{sum(correct)} / {len(correct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "soviet-quilt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f49a8914d00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = t_test_images[9496].cpu().reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "steady-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8, device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(net(img.flatten().float().unsqueeze(0).unsqueeze(0).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "palestinian-durham",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[60000, 10]' is invalid for input of size 60000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-93cb4da5433c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[60000, 10]' is invalid for input of size 60000"
     ]
    }
   ],
   "source": [
    "t_labels.reshape(60000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lined-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_images.reshape((60000, 784))[0] == t_images.flatten().reshape((60000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "meaning-ambassador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_labels[1:3].reshape(2,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "compact-admission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-heaven",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
