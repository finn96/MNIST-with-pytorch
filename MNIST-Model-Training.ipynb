{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "casual-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conventional-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's start by loading our data\n",
    "\n",
    "# Starting with the labels\n",
    "with open(\"./data/processed_training_labels.csv\") as labels_file:\n",
    "    labels_string = labels_file.read()\n",
    "    labels = np.array(labels_string.split(','), dtype=int)\n",
    "    \n",
    "# Recall we had 60000 images. Let's make sure we didn't lose anythin\n",
    "assert len(labels) == 60000\n",
    "\n",
    "# Now for the images\n",
    "images = []\n",
    "with open(\"./data/processed_training_images\") as images_file:\n",
    "    raw_image_strings = images_file.readlines()\n",
    "    for img_string in raw_image_strings:\n",
    "        img_flat = np.array(img_string.split(\",\"), dtype=np.double)\n",
    "        img = np.reshape(img_flat, (28,28))\n",
    "        images.append(img)\n",
    "        \n",
    "# Again, let's do some random spot checking to make sure everything is as we expect\n",
    "assert len(images) == 60000\n",
    "i1,i2,i3 = np.random.randint(0, 60000, 3)\n",
    "assert images[i1].shape == (28,28)\n",
    "assert images[i2].shape == (28,28)\n",
    "assert images[i3].shape == (28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "previous-drill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4c34fa3e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And again, we'll just print out some images and their labels for good measure \n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.add_subplot(1,4,1)\n",
    "plt.text(9,40,f\"label: {labels[i1]}\")\n",
    "plt.imshow(images[i1], cmap='gray')\n",
    "fig.add_subplot(1,4,2)\n",
    "plt.text(10,40,f\"label: {labels[i2]}\")\n",
    "plt.imshow(images[i2], cmap='gray')\n",
    "fig.add_subplot(1,4,3)\n",
    "plt.text(11,40,f\"label: {labels[i3]}\")\n",
    "plt.imshow(images[i3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "perfect-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Okay! Now the fun begins.\n",
    "# To start, let's just get everything over to Torch\n",
    "t_labels = torch.tensor(labels).long()\n",
    "t_images = torch.tensor(images)\n",
    "\n",
    "train_images = t_images.reshape(60000, 1, 784).float()\n",
    "train_labels = torch.zeros(60000, 1, 10)\n",
    "for i, label in enumerate(t_labels):\n",
    "    train_labels[i][0][label.item()] = 1\n",
    "\n",
    "#_ = train_images[:][:].div_(255.0)  # Normalize the pixel values to between [0,1.0]\n",
    "#train_labels = train_labels.flip(0)\n",
    "#train_images = train_images.flip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "egyptian-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4c34cab370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And we can take a look at their shapes\n",
    "import matplotlib.pyplot as plt\n",
    "z = np.random.randint(0, 60000)\n",
    "plt.imshow(train_images[z][0].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "pregnant-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: !DF! Try just one fully connected layer\n",
    "# TODO: !DF! Write explanation on MSELoss()\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1,1,3)  # stride = 1\n",
    "        #self.drop1 = nn.(389,p=.2) \n",
    "        self.fc1 = nn.Linear(782,100) # 80\n",
    "        #self.drop2 = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        #self.fc3 = nn.Linear(100, 10) # 80\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # https://towardsdatascience.com/why-data-should-be-normalized-before-training-a-neural-network-c626b7f66c7d\n",
    "        x = F.tanh(self.conv1(x))\n",
    "        #x = F.sigmoid(self.conv1(x))\n",
    "        #x = self.drop1(x)\n",
    "        x = x.view(-1, x.shape[1:].numel())  # Linear input should be in shape [batch_size, features x height x width]\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        #x = F.sigmoid(self.fc1(x))\n",
    "        \n",
    "        \n",
    "        #x = F.sigmoid(self.fc2(x))\n",
    "        #x = self.drop2(x)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        # What we're doing here is re-shaping x to remove the channel dimension. This was confusing for me to understand. But\n",
    "        # basically pytorch expects everything in mini batches. So incoming data is in the form (images_per_batch,\n",
    "        # channels_per_image, (h,w)). In our case, we have (4,1,784), because we have 4 images per batch, 1 channel per image,\n",
    "        # and a flat vector of length 784 representing that channel (and because we have only one channel, that image). Our\n",
    "        # output, however, is channel indepedent. We want our output to be in the shape (images_per_batch,\n",
    "        # {single_image_output_shape}). In that case, our final output shape is (4, 10)\n",
    "        return self.fc2(x)\n",
    "\n",
    "## 100 -> ~76 ~78 ~78 ~78%\n",
    "## 80 -> ~78 ~76 ~ 77 ~78%\n",
    "\n",
    "## 100 with max_pool -> 71%, 73% 71%\n",
    "#https://discuss.pytorch.org/t/how-are-layer-weights-and-biases-initialized-by-default/13073\n",
    "# 5 Epochs with +-[1/sqrt(n)] weights + pytorch bias, Sigmoid, Kernel Size 3: 85%, 86%, 86%\n",
    "# 5 Epochs with pytorch weights/bias, Sigmoid, Kernel Size 3: 87%, 86%, 86%, 85%\n",
    "# 5 Epochs with +-[1/sqrt(n)] weights + 0 bias, Sigmoid, Kernel Size 3: 86%, 86%, 86%, 85%\n",
    "# 5 Epochs with +-[1/sqrt(n)] weights and bias, Sigmoid, Kernel Size 3: 86%, 85%, 86%\n",
    "#  5 Epochs with Normalized Xavier weights and 0 bias, Sigmoid, Kernel Size 3: 87%, 87%, 86%,(5) -- 90.35% 90.44%  (10) **\n",
    "#  5 Epochs with Normalized Xavier weights and 0 bias, Sigmoid, Kernel Size 5: 86%, 86%, 86% (5) -- 89.31% 90.03%  (10)\n",
    "#  5 Epochs with Normalized Xavier weights and 0 bias, Sigmoid, Kernel Size 8: 87%, 86%, 87% (5) -- 89.79% 88.58%  (10)\n",
    "\n",
    "## TODO: !DF! Best of the normalized Xavier head-to-head with pytorch defaults, 10 epochs, track loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "elegant-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net\n",
    "# https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch\n",
    "# https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/\n",
    "# TODO:!DF! test with and without these weights\n",
    "#net.fc1.weight.data.uniform_(-1.0/np.sqrt(782),1.0/np.sqrt(782))\n",
    "#_ = net.fc2.weight.data.uniform_(-1.0/np.sqrt(100),1.0/np.sqrt(100))\n",
    "#net.fc1.bias.data.uniform_(-1.0/np.sqrt(782),1.0/np.sqrt(782))\n",
    "#_ =  net.fc2.bias.data.uniform_(-1.0/np.sqrt(100),1.0/np.sqrt(100))-np.sqrt(6.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "comprehensive-education",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Epoch: 2, Batch: 14999, running_loss: 75.85815699980594'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "criterion = nn.MSELoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "mb_size = 4\n",
    "num_batches = len(train_images) // mb_size\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    #for i in range(0,len(train_images), 4):\n",
    "    for i in range(0, num_batches):\n",
    "        net.zero_grad()\n",
    "        out = net.forward(train_images[i*mb_size:(i+1)*mb_size])\n",
    "            #loss = criterion(out, train_labels[i:i+4])\n",
    "        loss = criterion2(out, t_labels[i*mb_size:(i+1)*mb_size])\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "                ## I recommend doing things like this. It helped me catch mistakes\n",
    "                #print(batch[0][0])\n",
    "                #plt.imshow(batch[0][0].reshape((28,28)), cmap='gray')\n",
    "                #plt.show()\n",
    "                #print(targets[0])\n",
    "            clear_output(wait=True)\n",
    "            display(f\"Epoch: {epoch}, Batch: {i}, running_loss: {running_loss}\")\n",
    "            running_loss = 0.0\n",
    "        for f in net.parameters():\n",
    "            f.data = f.data - f.grad.data * .01\n",
    "                ####f.data.sub_(f.grad.data * 0.01)\n",
    "            #f.data.sub_(f.grad.data * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "motivated-difficulty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9454.6\n",
      "9480.0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "default_wb_results = copy.deepcopy(training_outs)\n",
    "#norm_xav_wb_results = copy.deepcopy(training_outs)\n",
    "print(np.mean(norm_xav_wb_results))\n",
    "print(np.mean(default_wb_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(net(t_images[750].flatten().float().unsqueeze(0).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "funky-yemen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1536,  0.2882, -0.4127, -0.0651,  0.3566,  0.1120, -0.2545,  0.0706,\n",
       "         -0.7031, -0.1304],\n",
       "        [ 0.1242,  0.2807, -0.4189, -0.0767,  0.3486,  0.1419, -0.2370,  0.0854,\n",
       "         -0.6636, -0.1226],\n",
       "        [ 0.1348,  0.2714, -0.3890, -0.0232,  0.3746,  0.1413, -0.2490,  0.0728,\n",
       "         -0.6497, -0.1143],\n",
       "        [ 0.0769,  0.2961, -0.3989, -0.0508,  0.3697,  0.1184, -0.2663,  0.0687,\n",
       "         -0.6492, -0.1373]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.view(4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sweet-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/processed_testing_labels.csv\") as labels_file:\n",
    "    labels_string = labels_file.read()\n",
    "    testing_labels = np.array(labels_string.split(','), dtype=int)\n",
    "    \n",
    "# Recall we had 60000 images. Let's make sure we didn't lose anythin\n",
    "assert len(testing_labels) == 10000\n",
    "\n",
    "# Now for the images\n",
    "testing_images = []\n",
    "with open(\"./data/processed_testing_images\") as images_file:\n",
    "    raw_image_strings = images_file.readlines()\n",
    "    for img_string in raw_image_strings:\n",
    "        img_flat = np.array(img_string.split(\",\"), dtype=np.double)\n",
    "        img = np.reshape(img_flat, (28,28))\n",
    "        testing_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exotic-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_labels = torch.tensor(testing_labels)\n",
    "t_test_images = torch.tensor(testing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "optical-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9603 / 10000\n"
     ]
    }
   ],
   "source": [
    "test_imgs = t_test_images\n",
    "test_labels = t_test_labels\n",
    "correct = []\n",
    "for i,img in enumerate(test_imgs):\n",
    "    res = torch.argmax(net(img.flatten().float().unsqueeze(0).unsqueeze(0)))\n",
    "    targ = test_labels[i]\n",
    "    if res == targ:\n",
    "        correct.append(1)\n",
    "    else:\n",
    "        correct.append(0)\n",
    "\n",
    "print(f\"{sum(correct)} / {len(correct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "soviet-quilt",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-91ac2a9860c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9496\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "img = t_images[9496]\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(net(img.flatten().float().unsqueeze(0).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "decreased-aluminum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1050,  0.4207,  0.8344,  8.9818, -2.0588,  2.4454, -7.6334, -3.6497,\n",
       "         2.2114, -0.3338], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "attended-possibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9],\n",
       "        [3],\n",
       "        [8],\n",
       "        [2]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "##torch.save(net, \"./models/1dC2fc85\")\n",
    "##torch.save(net.state_dict(), \"./models/1dC2fc85.state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.flip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_img = train_images[0][0]\n",
    "my_conv1d = nn.Conv1d(1,2,2)\n",
    "my_conv1d(my_img.unsqueeze(0).unsqueeze(0))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = nn.Conv1d(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "f(train_images[0].unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "104/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "stone-portfolio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0344, -0.0227, -0.0099,  ...,  0.0357,  0.0121, -0.0129],\n",
       "        [-0.0289, -0.0260, -0.0018,  ...,  0.0205, -0.0217,  0.0199],\n",
       "        [ 0.0091,  0.0305,  0.0191,  ..., -0.0006,  0.0047, -0.0305],\n",
       "        ...,\n",
       "        [-0.0057,  0.0190, -0.0134,  ..., -0.0067,  0.0096, -0.0161],\n",
       "        [ 0.0202, -0.0128, -0.0338,  ..., -0.0176, -0.0176,  0.0211],\n",
       "        [-0.0263, -0.0035,  0.0092,  ..., -0.0211, -0.0109, -0.0111]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = nn.Linear(782,100)\n",
    "ll2 = nn.Linear(782, 100)\n",
    "ll2.weight.data.uniform_(-1.0/np.sqrt(782),1.0/np.sqrt(782))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "requested-knight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6307e-05)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.weight.data.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "neither-marking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-8.7258e-05)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll2.weight.data.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "southern-school",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.weight.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "useful-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "threaded-binary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 15000, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "christian-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[0][0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "temporal-profit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "reduced-graphic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "upper-realtor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "pointed-papua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_labels.size()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "social-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "sonic-basics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[ 1.5822,  2.0050, -0.5929]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.1087], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0119, -0.0085,  0.0110,  ...,  0.0116, -0.0096, -0.0135],\n",
       "         [-0.0320,  0.0286, -0.0208,  ..., -0.0038, -0.0199, -0.0130],\n",
       "         [-0.0223,  0.0322,  0.0007,  ..., -0.0159, -0.0188, -0.0315],\n",
       "         ...,\n",
       "         [-0.0292,  0.0170,  0.0317,  ...,  0.0107, -0.0131, -0.0099],\n",
       "         [ 0.0201, -0.0065,  0.0112,  ..., -0.0329, -0.0110, -0.0011],\n",
       "         [-0.0252, -0.0218, -0.0027,  ...,  0.0336,  0.0312, -0.0325]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0291,  0.0315,  0.0305, -0.0010,  0.0330,  0.0426, -0.0345,  0.0205,\n",
       "         -0.0040,  0.0300, -0.0284,  0.0403, -0.0158,  0.0218,  0.0196, -0.0311,\n",
       "          0.0297,  0.0403, -0.0171,  0.0373,  0.0035,  0.0131,  0.0121, -0.0083,\n",
       "          0.0167, -0.0325, -0.0125,  0.0208, -0.0074,  0.0100,  0.0063,  0.0023,\n",
       "         -0.0191, -0.0409,  0.0187,  0.0119,  0.0230,  0.0542, -0.0017, -0.0182,\n",
       "         -0.0049, -0.0191, -0.0290,  0.0102, -0.0125, -0.0276,  0.0201,  0.0289,\n",
       "          0.0089,  0.0384,  0.0261,  0.0032,  0.0115,  0.0233, -0.0097, -0.0288,\n",
       "         -0.0247, -0.0021, -0.0066,  0.0253, -0.0046, -0.0194,  0.0415,  0.0067,\n",
       "         -0.0154, -0.0367,  0.0342,  0.0213, -0.0159, -0.0201,  0.0397, -0.0207,\n",
       "         -0.0295, -0.0045,  0.0093,  0.0454, -0.0382, -0.0282,  0.0014,  0.0213,\n",
       "          0.0137, -0.0092,  0.0209,  0.0034, -0.0119, -0.0071, -0.0023, -0.0114,\n",
       "         -0.0173, -0.0470,  0.0109, -0.0405,  0.0175,  0.0137,  0.0277,  0.0030,\n",
       "          0.0244, -0.0079,  0.0283, -0.0333], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.0258e-03,  5.2314e-02, -4.5423e-02,  1.5536e-01,  4.6427e-02,\n",
       "          -2.5485e-01,  2.1412e-02, -7.9930e-03,  1.4188e-01,  4.3846e-01,\n",
       "          -1.9172e-01, -1.5980e-01,  5.2889e-02,  5.1682e-02, -2.0219e-02,\n",
       "           7.4584e-02,  1.7887e-01, -3.9276e-02,  2.7752e-01, -5.3229e-02,\n",
       "          -9.7377e-03,  1.3718e-02, -1.5890e-01,  2.2185e-01,  1.2075e-01,\n",
       "           5.0346e-01, -6.2454e-02, -2.2633e-01,  1.6712e-02,  3.1893e-01,\n",
       "           5.3911e-02, -3.5876e-01, -1.3212e-01,  2.6533e-01, -4.5288e-01,\n",
       "          -1.9184e-01,  1.5420e-01, -6.8150e-02, -9.7781e-02, -3.3338e-01,\n",
       "          -3.1908e-01,  2.4769e-01, -1.0298e-01, -1.6138e-01, -3.2818e-01,\n",
       "          -3.1589e-01, -2.5064e-03, -4.4193e-01, -3.3526e-01, -5.9692e-02,\n",
       "           1.6478e-01, -2.5615e-01, -3.2051e-02,  4.6534e-01,  2.3161e-01,\n",
       "           1.3709e-01,  3.8667e-01,  1.7615e-01,  2.3169e-01, -3.5072e-01,\n",
       "           3.0461e-01,  2.1399e-01,  1.5810e-01, -1.7082e-02, -9.4667e-02,\n",
       "          -7.4696e-02,  6.0414e-02,  2.8499e-01,  2.2221e-02, -1.1866e-01,\n",
       "          -1.1483e-01, -3.2429e-01,  2.5374e-01,  5.5751e-02,  4.2369e-01,\n",
       "          -1.5517e-01, -1.2166e-01, -3.1338e-01, -1.3274e-01, -3.8521e-02,\n",
       "          -8.2280e-02, -1.8564e-01, -4.3067e-01, -4.6088e-01, -2.4109e-01,\n",
       "          -6.7576e-02,  3.4374e-01, -1.7902e-01,  1.8433e-02,  3.6156e-01,\n",
       "           1.0913e-01,  1.6634e-01,  1.0724e-01, -8.3659e-02, -8.6611e-02,\n",
       "           1.2281e-01, -7.9654e-02, -3.1234e-01, -2.5148e-01,  1.0234e-01],\n",
       "         [ 1.2152e-01, -2.5434e-01,  1.5359e-03,  1.4021e-01,  5.7936e-02,\n",
       "          -2.9978e-01,  8.4915e-02,  1.3874e-02, -8.5623e-03, -1.5184e-02,\n",
       "           2.4282e-01,  3.7812e-01, -1.2481e-01, -1.8944e-04, -3.8465e-01,\n",
       "           1.5324e-01, -2.4513e-01, -2.0585e-01, -2.4892e-01,  2.2080e-01,\n",
       "           1.9291e-01, -1.1610e-01,  5.3531e-01, -2.1775e-01, -3.3710e-01,\n",
       "          -1.9394e-01,  1.7558e-02,  1.7000e-01, -2.7802e-01, -1.5170e-01,\n",
       "           2.1537e-01,  4.5959e-02,  2.2530e-01, -1.2241e-01,  2.2116e-01,\n",
       "           3.2271e-01,  3.7488e-01, -3.8177e-01,  4.9150e-02,  4.5160e-01,\n",
       "           2.4800e-01, -2.1036e-01, -2.4726e-01,  1.3829e-01,  2.1234e-01,\n",
       "           2.7762e-01,  1.5860e-01,  1.3931e-01,  2.9744e-02, -7.8919e-02,\n",
       "          -1.7506e-01,  4.0531e-01,  1.2331e-01, -3.7660e-01, -3.8763e-01,\n",
       "           1.7878e-01,  2.9947e-01,  1.7081e-02, -6.5856e-02,  1.7689e-01,\n",
       "          -4.8061e-02,  1.1903e-01, -1.6743e-01, -1.5054e-01,  1.7864e-01,\n",
       "           1.7809e-01,  1.9446e-01, -4.0370e-02,  2.6921e-01,  1.4642e-01,\n",
       "          -1.2777e-01,  1.3383e-01,  3.2232e-01, -8.8843e-02, -8.0283e-02,\n",
       "           2.4186e-01, -2.7853e-01, -8.2225e-02, -3.6702e-02,  6.1907e-02,\n",
       "           2.4653e-01,  3.9793e-01,  2.1220e-01, -3.2535e-01,  2.9088e-01,\n",
       "          -3.3602e-01, -1.3216e-01,  9.4619e-02,  1.0332e-01, -1.8974e-01,\n",
       "           1.4276e-01, -9.8881e-02,  3.8221e-01,  1.4198e-02, -3.2605e-02,\n",
       "          -1.7779e-01, -2.3493e-01, -1.4415e-01,  3.0294e-01, -2.4184e-01],\n",
       "         [ 1.5807e-01, -1.3919e-01, -2.4518e-01, -2.9360e-01,  6.0329e-02,\n",
       "          -1.4349e-01, -9.6500e-02,  4.4365e-01,  1.3704e-01, -3.6247e-01,\n",
       "          -2.2887e-01, -2.7873e-01, -1.5225e-01, -5.6926e-02, -1.6863e-02,\n",
       "          -2.7041e-02, -2.5792e-01,  3.9969e-01, -1.3295e-01,  3.2811e-01,\n",
       "           2.8233e-01,  2.3530e-01, -8.6704e-02,  1.6883e-01,  1.7113e-01,\n",
       "           2.4650e-01, -1.2005e-01,  4.3123e-02,  3.0854e-02,  1.4604e-01,\n",
       "           1.6162e-01, -3.1922e-02, -1.5505e-01, -2.9353e-01, -2.0193e-01,\n",
       "           3.7414e-01,  2.5059e-01, -3.9929e-01, -2.4831e-01, -4.4080e-01,\n",
       "           2.1862e-01, -4.3507e-01,  1.7970e-01,  4.9061e-01,  1.0708e-01,\n",
       "          -6.1464e-01, -3.5975e-01,  1.7931e-01,  3.2877e-01,  7.1033e-01,\n",
       "           5.1519e-01,  2.2333e-01, -1.8268e-02, -4.0543e-02, -1.1401e-01,\n",
       "          -5.0501e-01,  2.7543e-02, -3.0559e-01,  5.1533e-01,  3.0282e-01,\n",
       "          -1.5862e-01, -1.5829e-01, -2.0434e-01,  1.2981e-01, -1.5978e-01,\n",
       "           3.8879e-02, -1.5823e-02,  3.2371e-01, -1.4969e-01,  2.2409e-01,\n",
       "           4.2698e-01, -7.3731e-01, -2.8973e-01, -4.2535e-01, -2.1713e-01,\n",
       "          -1.4269e-01, -3.3192e-01, -1.5995e-01, -2.6034e-02, -2.7331e-01,\n",
       "          -1.6017e-01,  5.3479e-02, -2.8821e-02,  8.3014e-04, -4.4950e-02,\n",
       "          -8.5980e-01, -3.7816e-02,  3.6677e-02, -5.2157e-01,  2.5989e-01,\n",
       "          -4.5269e-01, -1.7978e-01,  4.5474e-01, -2.4991e-01, -1.5643e-01,\n",
       "           3.9349e-01, -1.3528e-01,  1.5577e-03,  2.1978e-01,  9.9117e-02],\n",
       "         [ 2.5321e-01,  1.9242e-01, -1.5510e-01, -7.2513e-02,  2.8637e-01,\n",
       "           2.5497e-01, -2.7463e-01, -9.8271e-02,  6.8077e-02, -1.7061e-01,\n",
       "           6.3855e-02,  3.3622e-01,  2.6581e-01, -1.0222e-01,  2.0152e-01,\n",
       "           1.6850e-01, -2.5024e-01,  1.2240e-01, -1.2883e-01,  1.4647e-01,\n",
       "          -3.3711e-03,  1.5725e-01,  1.2701e-01, -3.3027e-01, -3.1703e-01,\n",
       "           6.1790e-02, -3.9262e-01, -4.2977e-01,  2.6584e-01, -3.6032e-01,\n",
       "          -3.2456e-01,  2.2851e-01, -3.8735e-01, -1.9678e-01,  1.1802e-01,\n",
       "          -2.6224e-01, -2.3692e-01,  2.2859e-01, -2.6485e-01, -3.1533e-01,\n",
       "          -2.6130e-02,  2.6137e-01,  2.6847e-01, -1.5167e-01,  1.3831e-01,\n",
       "           1.9999e-01, -2.7218e-01,  3.1338e-01, -6.6922e-02,  1.8886e-01,\n",
       "          -2.7494e-01, -4.1565e-01,  3.1184e-01, -2.1474e-01, -4.3863e-02,\n",
       "           9.7346e-02, -2.5373e-01, -3.1278e-01,  3.7980e-01, -1.3150e-01,\n",
       "          -1.4865e-01, -2.5977e-01, -3.3692e-01,  7.8937e-02,  4.2127e-01,\n",
       "          -2.3297e-01,  2.5464e-02, -2.3311e-01, -2.8304e-01, -4.3289e-02,\n",
       "          -1.5448e-01,  1.4407e-01,  6.7188e-02,  1.4884e-01,  2.5420e-01,\n",
       "           3.9687e-01, -5.1188e-01,  1.8706e-02, -8.6669e-02, -2.7203e-01,\n",
       "           2.4242e-01,  3.2356e-01, -3.0879e-01,  6.5730e-02,  1.9708e-01,\n",
       "          -9.9230e-02, -2.2766e-01,  1.5493e-01,  3.4279e-01, -2.3940e-01,\n",
       "           1.4646e-01, -2.2507e-01,  1.7403e-01,  4.3409e-01, -1.4169e-01,\n",
       "           2.0344e-01,  5.3246e-01,  8.9019e-03,  1.2634e-01,  3.4580e-02],\n",
       "         [-7.2224e-02,  3.1136e-02, -5.1238e-02,  9.3574e-02, -3.2876e-01,\n",
       "           3.5907e-01, -1.3809e-01,  5.5996e-01,  1.6195e-01,  3.5724e-01,\n",
       "           4.8648e-01, -3.3070e-01, -3.8781e-01,  4.6618e-01,  2.8940e-01,\n",
       "          -1.1479e-01,  6.4413e-02, -1.2388e-01,  8.4395e-02,  2.4944e-01,\n",
       "           2.1436e-02, -2.3086e-01, -1.1388e-01,  1.1414e-01, -4.6255e-01,\n",
       "          -3.3265e-01,  4.8897e-01,  3.3743e-01,  2.3111e-01,  1.4780e-01,\n",
       "           3.6097e-01,  2.8574e-01,  1.5050e-01, -8.1685e-02,  9.4376e-02,\n",
       "          -3.8540e-02, -8.6795e-02,  1.7945e-01, -1.9866e-01,  1.7843e-01,\n",
       "           3.1582e-01, -1.1604e-02, -3.3643e-01,  1.5071e-01, -2.3637e-01,\n",
       "           3.8339e-01, -2.5554e-01, -8.4059e-02, -1.4492e-01, -2.1266e-01,\n",
       "          -3.2573e-01,  2.4327e-01, -4.0991e-01,  8.9642e-03,  2.3285e-01,\n",
       "          -2.4678e-01, -2.8954e-01,  2.0292e-01, -1.8543e-01,  2.3475e-01,\n",
       "           3.3820e-02,  1.3787e-02, -2.3375e-02,  1.4729e-02, -1.9821e-02,\n",
       "          -1.9167e-01, -5.1621e-01, -4.1878e-01,  2.2205e-01, -7.6606e-02,\n",
       "          -2.0111e-01,  1.4441e-01, -1.1375e-01,  2.7344e-01,  5.8827e-02,\n",
       "          -1.4141e-01,  3.8083e-01,  1.5296e-01,  4.7006e-01,  2.6611e-01,\n",
       "          -2.7268e-01,  2.7111e-01,  3.0605e-01,  9.1144e-02, -5.7035e-02,\n",
       "           2.7537e-01,  4.8006e-01,  3.3333e-01, -1.5782e-01,  2.4330e-01,\n",
       "          -5.7154e-01, -2.0885e-01, -3.5618e-01,  1.8903e-02,  4.0584e-01,\n",
       "           1.6771e-01,  7.5905e-02, -8.9794e-02,  1.8415e-01, -3.3162e-01],\n",
       "         [-7.7363e-01,  1.6377e-01,  5.2378e-02,  3.5903e-02,  1.6996e-01,\n",
       "           3.3086e-01,  2.3696e-01, -5.8980e-01,  1.0886e-01, -4.0518e-01,\n",
       "          -1.5974e-01,  3.4140e-01,  1.6131e-01,  3.1014e-01, -3.3283e-01,\n",
       "          -2.6189e-01,  2.3153e-02, -7.4064e-02, -5.3928e-02, -3.3911e-01,\n",
       "          -7.9568e-01, -1.3990e-01,  1.9336e-02, -1.9392e-01,  3.6937e-01,\n",
       "          -4.6351e-01,  1.0562e-01, -2.8038e-01, -1.4176e-01, -5.3793e-01,\n",
       "           2.3258e-01,  1.9307e-01, -9.5475e-02,  9.3109e-02,  7.6897e-02,\n",
       "          -1.0997e-01,  1.4127e-01,  1.7451e-01,  7.2986e-01,  2.3930e-02,\n",
       "           8.2826e-02,  2.2799e-01, -2.4162e-01,  1.2979e-01,  2.8641e-03,\n",
       "           7.7875e-02,  5.5455e-01,  4.5738e-01,  1.9388e-01, -3.2419e-01,\n",
       "           5.1528e-02, -5.1368e-01, -4.3605e-01, -3.9757e-01, -9.3726e-02,\n",
       "          -3.8914e-02, -1.3688e-01, -1.0116e-01, -5.7687e-01,  4.1897e-02,\n",
       "          -3.1171e-01, -3.1160e-01,  3.4089e-01, -4.3088e-03, -4.2413e-01,\n",
       "          -1.9333e-01,  8.6269e-02, -1.4820e-01, -3.5779e-01, -6.9072e-02,\n",
       "           1.5347e-01,  2.5627e-02, -2.0683e-02, -2.5528e-01, -3.8902e-01,\n",
       "           6.4160e-02,  5.6737e-01,  1.7260e-01, -2.4080e-01,  3.3277e-02,\n",
       "           1.5283e-01, -3.8327e-01, -6.6809e-02,  3.0259e-01,  1.7131e-01,\n",
       "           1.8312e-01, -3.9057e-01, -4.0706e-01,  2.8843e-01,  1.3198e-02,\n",
       "           2.6648e-01,  3.4410e-01, -2.1802e-01,  1.2194e-01, -1.3283e-01,\n",
       "           2.9480e-01, -1.4581e-03, -1.6211e-01, -3.5440e-01, -4.4964e-02],\n",
       "         [-3.1242e-01, -2.5050e-01, -7.9347e-02,  8.0039e-02, -1.8992e-01,\n",
       "          -3.1815e-01,  3.6781e-01, -2.9586e-01, -1.9390e-01,  3.0456e-01,\n",
       "          -9.5997e-02,  1.9796e-01,  4.6312e-02, -3.8940e-01,  3.3505e-01,\n",
       "          -4.3019e-01,  2.9032e-02, -1.0882e-01,  8.2107e-03, -3.4235e-01,\n",
       "          -1.3130e-01,  3.2327e-01, -2.8698e-01,  1.2776e-01, -8.5636e-03,\n",
       "           5.6175e-01,  2.7749e-01,  5.7954e-02, -4.6543e-02,  2.4464e-01,\n",
       "          -5.2822e-01, -2.0310e-01, -6.6712e-02, -1.4214e-01,  1.1201e-01,\n",
       "           2.8202e-01, -1.3285e-01, -1.6763e-01, -6.2820e-02,  3.0616e-01,\n",
       "          -3.1921e-01,  3.3042e-01,  2.4180e-01,  2.7016e-01,  3.2148e-01,\n",
       "          -3.4010e-01, -1.6814e-01, -3.1320e-01, -9.5966e-02, -1.6948e-01,\n",
       "           2.5358e-01,  1.3523e-01, -4.1037e-02,  8.8797e-03,  2.2558e-01,\n",
       "           5.0566e-02,  1.9994e-01,  3.7301e-01, -3.8841e-01,  2.0923e-01,\n",
       "           2.4714e-01,  2.2735e-01,  1.3313e-01, -3.9094e-01, -1.3967e-01,\n",
       "           2.1397e-01, -9.4659e-02,  5.0379e-02,  1.7653e-01,  2.3688e-01,\n",
       "          -2.0347e-01,  1.5779e-02,  1.2553e-01,  1.4358e-01, -2.4932e-01,\n",
       "          -1.8280e-01, -1.6618e-01,  1.7621e-01, -1.4516e-01,  3.2728e-01,\n",
       "          -2.2153e-01,  1.6473e-01,  3.6833e-02,  1.2901e-01,  4.4483e-02,\n",
       "           2.8699e-01, -3.6076e-01, -3.8570e-02,  2.4029e-01,  5.8799e-02,\n",
       "          -2.8250e-01,  1.1122e-01, -1.3252e-01, -2.0125e-01,  3.3209e-01,\n",
       "           2.2218e-01, -2.7481e-01, -1.6382e-01, -1.5001e-01, -1.2215e-01],\n",
       "         [ 1.4749e-01,  4.8784e-01,  2.2438e-02,  1.0347e-01,  1.5674e-01,\n",
       "           9.9954e-03, -4.7050e-01,  1.4788e-01,  3.9714e-01,  1.5014e-01,\n",
       "          -2.3245e-04, -3.2755e-01,  3.0861e-02, -9.4749e-02, -3.9775e-01,\n",
       "           2.7059e-01,  1.4947e-01, -1.4750e-01, -3.8402e-02, -5.3215e-02,\n",
       "           1.6821e-01, -2.6740e-01, -3.7965e-01,  2.4398e-01, -2.2323e-01,\n",
       "          -4.4742e-01, -1.1056e-01,  6.1132e-01, -2.5062e-01, -3.4312e-01,\n",
       "          -1.2496e-01, -5.2995e-01,  2.2016e-02,  4.0823e-02, -2.0627e-01,\n",
       "           1.7985e-01, -1.7979e-01,  1.9525e-01, -9.1846e-02, -3.9496e-01,\n",
       "          -8.0551e-02,  8.6591e-02, -1.3378e-01, -2.4592e-01,  4.0903e-02,\n",
       "          -2.5688e-01,  4.7983e-02,  7.8085e-02,  3.1842e-01, -1.2480e-01,\n",
       "          -3.1668e-01,  2.2160e-01, -1.1943e-01,  4.2378e-01, -2.8466e-02,\n",
       "           2.7155e-01, -1.2887e-01, -2.4659e-01, -2.8535e-02, -4.9145e-01,\n",
       "           1.1802e-01, -2.0011e-01, -4.7476e-01, -3.7456e-02,  1.2488e-02,\n",
       "          -1.5176e-01, -2.5114e-01, -1.7766e-01,  4.2463e-02, -1.3157e-01,\n",
       "          -2.8263e-01,  2.1213e-01,  1.5254e-01, -2.5745e-01, -2.0821e-01,\n",
       "           4.9325e-01, -2.3012e-01, -3.0342e-01,  3.2101e-01, -3.8625e-01,\n",
       "           2.2119e-01, -1.9049e-02,  3.9953e-01,  8.8059e-02,  6.4298e-03,\n",
       "           1.6315e-01,  1.2555e-01, -2.8884e-01, -6.4247e-01, -2.8923e-01,\n",
       "           1.5984e-01, -3.9542e-01, -1.1030e-01,  1.2245e-01, -1.5548e-01,\n",
       "          -3.5454e-01,  1.4848e-01,  4.9566e-01, -2.1885e-01,  1.9241e-01],\n",
       "         [ 3.2533e-01,  3.2352e-01, -7.2855e-02,  3.1560e-01, -2.9552e-01,\n",
       "          -2.6372e-01,  1.3223e-01,  3.6208e-01, -3.0742e-01,  1.1317e-02,\n",
       "          -6.2111e-01,  2.1682e-01, -3.2117e-02,  1.6174e-02,  6.6725e-02,\n",
       "          -3.0453e-02, -1.1591e-01,  7.4270e-02,  2.4077e-01,  4.9175e-02,\n",
       "          -5.4453e-02,  1.7206e-01,  2.3693e-01, -3.9472e-01,  4.6541e-01,\n",
       "           7.6701e-02,  1.9320e-01, -5.9408e-02,  2.6056e-01,  5.9109e-01,\n",
       "           2.1019e-01,  3.2528e-01,  3.2258e-01, -2.9890e-01, -2.8766e-01,\n",
       "          -7.4301e-02, -9.4183e-02, -7.5399e-02, -8.1019e-02,  3.0151e-01,\n",
       "           5.8981e-03, -2.2702e-01,  1.8445e-01, -3.6164e-01, -1.2887e-02,\n",
       "           2.0214e-01, -1.4236e-01,  2.8688e-01, -9.6308e-02, -2.4685e-01,\n",
       "           2.7248e-01,  2.6191e-01,  3.8414e-01,  1.3264e-01, -4.2480e-01,\n",
       "           3.7323e-02, -1.2967e-01,  2.4483e-01, -8.3828e-02,  7.8553e-02,\n",
       "           1.1170e-01, -1.9115e-01, -1.0993e-01,  2.9363e-02, -1.6341e-02,\n",
       "           2.4278e-01,  5.8713e-01,  9.1579e-02, -1.7694e-02, -1.9422e-03,\n",
       "           3.1603e-01,  3.7575e-01, -3.5745e-01,  1.4287e-01, -6.1222e-02,\n",
       "          -2.8641e-01,  3.5860e-01,  3.3433e-01,  4.4334e-03,  2.1278e-01,\n",
       "           1.5599e-01, -3.1840e-02,  3.4467e-01,  7.9518e-02, -1.4776e-01,\n",
       "           1.6208e-01,  2.4777e-01,  2.5802e-01,  2.3519e-01, -1.6146e-01,\n",
       "           1.9061e-01,  5.0592e-01, -3.3962e-01, -3.6161e-01, -2.3549e-01,\n",
       "          -2.6296e-01, -4.7797e-02,  7.4629e-02, -1.4636e-01,  3.3378e-01],\n",
       "         [ 3.3779e-01, -2.9251e-01,  4.2572e-01, -2.5700e-01,  1.5064e-01,\n",
       "           3.4919e-01,  3.2369e-01, -1.6441e-01, -3.9647e-01, -6.8118e-02,\n",
       "           4.9503e-01, -3.7914e-01, -1.3434e-01, -1.4256e-02,  2.5724e-01,\n",
       "           4.3213e-01,  1.6026e-01, -1.1529e-01, -8.9376e-02,  1.8799e-01,\n",
       "           2.1776e-01, -6.8007e-02,  1.5723e-02,  2.0316e-01,  4.1846e-01,\n",
       "           2.6541e-02, -2.1910e-01, -2.2734e-02, -6.0232e-02, -1.0002e-01,\n",
       "          -2.1613e-02,  3.0543e-02, -1.4410e-01,  5.3321e-01,  3.6009e-01,\n",
       "          -2.9612e-01, -2.1027e-01,  2.4827e-01, -1.2729e-01,  2.7618e-01,\n",
       "           1.0295e-01, -3.1930e-01,  2.5441e-01, -4.3775e-01, -2.2710e-01,\n",
       "           4.6969e-01,  2.6699e-01, -3.7061e-01, -2.4730e-01, -1.5625e-01,\n",
       "          -3.7099e-01,  4.8083e-02,  3.5012e-01, -1.7070e-01,  1.8394e-01,\n",
       "           1.2808e-01, -1.5328e-01, -9.4785e-02,  2.0721e-01,  1.7142e-01,\n",
       "          -1.4576e-01,  1.8519e-01,  6.7146e-01,  1.7904e-01,  2.6343e-01,\n",
       "          -2.6555e-01, -7.8406e-02,  2.4719e-01,  3.4333e-01, -3.4417e-01,\n",
       "          -8.7780e-02,  1.3909e-01, -2.2654e-01,  2.5625e-01,  2.9981e-01,\n",
       "          -3.2771e-01,  3.6495e-02, -1.8806e-02, -1.3151e-01,  3.0458e-01,\n",
       "          -3.6701e-01, -4.8125e-01, -1.8916e-01,  8.5217e-02, -1.3584e-01,\n",
       "           6.6476e-02,  2.3475e-01, -5.1097e-02,  2.5636e-01, -2.6569e-01,\n",
       "           2.7942e-01, -9.3178e-02, -1.4127e-01,  2.0957e-01, -2.4523e-01,\n",
       "          -5.4476e-01,  1.5772e-01,  9.5542e-02,  1.6137e-01,  3.9587e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0090,  0.0056,  0.1366, -0.0656, -0.0155,  0.0458, -0.0476,  0.0843,\n",
       "         -0.1415, -0.0733], requires_grad=True)]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "invalid-elite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0080, -0.0141,  0.0383, -0.0103,  0.0013,  0.0218, -0.0356, -0.0228,\n",
       "        -0.0382, -0.0159, -0.0151,  0.0460, -0.0070,  0.0435, -0.0254, -0.0147,\n",
       "        -0.0032,  0.0105, -0.0077,  0.0004, -0.0047, -0.0055, -0.0339,  0.0173,\n",
       "        -0.0308, -0.0061,  0.0225, -0.0354, -0.0293, -0.0048, -0.0192, -0.0218,\n",
       "         0.0065,  0.0266, -0.0079, -0.0133,  0.0077,  0.0481, -0.0287,  0.0276,\n",
       "        -0.0239,  0.0289, -0.0095, -0.0055, -0.0284, -0.0274,  0.0205,  0.0408,\n",
       "         0.0140, -0.0043,  0.0287, -0.0078,  0.0090,  0.0165, -0.0393,  0.0231,\n",
       "        -0.0165, -0.0010, -0.0238,  0.0230,  0.0002, -0.0006, -0.0164,  0.0537,\n",
       "         0.0321,  0.0053, -0.0277,  0.0187,  0.0066, -0.0011,  0.0217,  0.0270,\n",
       "        -0.0283, -0.0403,  0.0196,  0.0299, -0.0023,  0.0104, -0.0132,  0.0106,\n",
       "         0.0119,  0.0370,  0.0017,  0.0263,  0.0404, -0.0017, -0.0151,  0.0179,\n",
       "        -0.0050, -0.0308,  0.0082, -0.0037, -0.0387,  0.0266,  0.0246, -0.0437,\n",
       "        -0.0268, -0.0049,  0.0263, -0.0295], requires_grad=True)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "necessary-course",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0761e+00, -1.6235e+01,  2.8565e+01, -2.9188e+01,  5.7104e+01,\n",
       "          2.5931e+01,  1.0913e+02, -4.0174e+01,  3.4021e+01, -3.2643e+00,\n",
       "          1.5213e+02, -6.2860e+01, -2.4384e+01,  3.4705e+01,  1.7448e+02,\n",
       "         -7.2245e+01,  3.1114e+01, -6.9633e+01,  4.0884e+02, -2.2795e+01,\n",
       "         -5.0592e+00, -5.0908e+01, -2.6636e+01,  3.7254e+01, -7.3828e+01,\n",
       "          9.6459e+01,  6.2397e+01,  3.0369e+01,  2.6805e+01,  2.2060e+01,\n",
       "         -1.1421e+01, -5.5894e+01,  6.9189e+01,  1.8263e+01, -4.3208e+01,\n",
       "         -3.9489e+00, -3.2699e+01,  2.0531e+01,  8.4536e+00,  9.1575e+01,\n",
       "          1.6691e+01,  3.2863e+01, -1.0319e+02, -2.1753e+00, -3.5632e+01,\n",
       "         -9.1058e+01, -1.3955e+01, -3.4793e+01, -3.9361e+01,  1.4621e+01,\n",
       "          6.0975e+01,  1.9006e+01,  4.7710e+01, -4.9742e+01,  1.2436e+01,\n",
       "          1.6198e+01, -7.0281e+00,  2.7315e+01,  2.5393e+01, -5.8661e+01,\n",
       "          1.7992e+01,  2.6399e+02,  5.6909e+00, -1.4564e+01,  2.7287e+01,\n",
       "         -2.3878e+01,  1.9201e+02,  3.7534e+01, -1.4834e+02, -1.7137e+01,\n",
       "          5.9946e+01, -3.2439e+01,  2.1900e+01, -1.0830e+01,  5.5036e+01,\n",
       "          2.6049e+01,  4.2267e+01,  8.9683e+01, -2.9262e+01, -4.2697e+01,\n",
       "         -2.0576e+01, -2.7347e+01, -2.2184e+01,  4.3418e+01,  3.4864e+01,\n",
       "         -9.5323e+01, -5.8547e+00,  2.2754e+02, -2.3670e+01,  2.2805e+01,\n",
       "         -8.9867e+01,  3.1030e+01, -5.2088e+00,  4.5674e+01, -1.5165e+02,\n",
       "         -1.7612e+01, -5.3979e+01, -1.2877e+02, -3.7780e+02,  4.2549e+01],\n",
       "        [ 6.3888e+01,  6.3495e+00,  2.1252e+01, -1.7166e+02, -2.1891e+01,\n",
       "         -1.0906e+02, -6.9815e+01, -8.9468e+01,  2.1744e+01, -1.7615e+01,\n",
       "         -6.4894e+01, -5.8981e+01,  2.5228e+01,  9.5426e+00, -9.1179e+01,\n",
       "          1.0559e+02, -1.3284e+02,  8.3737e+00, -1.5286e+02,  1.8807e+02,\n",
       "          7.7380e+01,  2.2341e+02,  1.0428e+02, -3.4822e+02,  1.1122e+02,\n",
       "         -1.5712e+02, -5.2405e+00, -3.6342e+01, -2.5043e+02,  5.7740e+00,\n",
       "          1.9851e+01,  1.6995e+02,  9.8667e+01,  4.2622e+01,  4.2894e+01,\n",
       "          1.7359e+02,  5.8633e+01,  5.9647e+00, -3.6040e+01, -2.3356e+02,\n",
       "          1.0764e+02, -6.9488e+01,  4.9572e+01,  9.7755e+00, -1.3095e+02,\n",
       "         -1.6551e+01, -1.1087e+01, -6.9502e+01, -4.4153e+01, -1.4967e+02,\n",
       "         -6.6506e+01, -2.6192e+02,  3.4045e+01, -5.5812e+01,  1.3992e+02,\n",
       "          3.3856e+00,  5.4832e+01, -5.4881e+01,  6.3696e+01, -1.7658e+01,\n",
       "          1.2622e+01, -1.1612e+02,  5.3447e+01, -2.3043e+01, -1.3549e+01,\n",
       "          3.5023e+00, -2.1186e+02, -1.9198e+01,  5.9682e+01, -2.5030e+01,\n",
       "          1.6369e+02,  1.5582e+02,  5.9436e+01,  7.5980e+00,  4.5135e+01,\n",
       "         -1.3084e+02,  7.0311e+01, -8.2911e+01,  1.4543e+01, -6.5215e+01,\n",
       "         -9.9081e+00,  2.9498e+01, -1.1631e+00, -6.6350e+01, -3.7190e+01,\n",
       "          1.1965e+02, -3.1738e+01, -2.3251e+01, -6.9955e+01,  7.4448e+01,\n",
       "          1.9038e+02,  5.4964e+01,  4.4082e+02,  2.6534e+01,  2.1227e+02,\n",
       "         -2.3474e+01,  2.5090e+01,  2.9427e+02,  4.7510e+02, -4.5985e+01],\n",
       "        [-3.4220e+01, -3.7699e+01, -5.7732e+01,  1.0453e+02,  1.3914e+01,\n",
       "         -1.6358e+01, -6.2125e+00, -1.9574e+01, -3.0001e+01,  3.6697e+00,\n",
       "          1.0901e+02,  2.3302e+01,  2.1052e+01,  1.7131e+00, -1.7042e+02,\n",
       "          7.4555e+01, -5.3177e+01,  6.8059e+01, -7.5604e+01, -1.7762e+01,\n",
       "          5.4652e+01, -2.5319e+01, -4.4725e+01, -3.8783e+01,  5.3560e+01,\n",
       "         -4.4991e+01,  1.1717e+02, -3.9205e+01, -6.6223e+01,  3.5675e+01,\n",
       "          7.7170e+01, -5.3963e+01, -1.1177e+02, -5.3996e+01,  6.7670e+00,\n",
       "         -1.7888e+02, -5.3951e+00, -2.2224e+01, -1.8310e+01,  4.5177e+01,\n",
       "         -5.4914e+01, -1.0899e+02,  5.6115e+01,  4.0709e+00, -3.6717e+01,\n",
       "         -3.2330e+01, -2.3227e+02, -3.9899e+01,  1.1356e+01, -7.8504e+01,\n",
       "          3.5307e+00,  2.0757e+01, -1.4149e+01,  4.6780e+01, -7.0604e+00,\n",
       "         -3.3002e+01, -3.1054e+01, -3.7885e+01, -8.8581e+01, -1.4397e+01,\n",
       "          1.3218e+01, -3.5052e+02, -3.2412e+01,  8.6499e+01, -6.6372e+00,\n",
       "          1.0550e+01, -6.1640e+01, -2.3846e+01, -7.2797e+00, -4.6906e+01,\n",
       "         -9.0025e+01,  4.1073e+01, -2.8510e+01, -2.4671e+01,  1.2466e+01,\n",
       "         -5.8403e+01,  2.5882e+01, -1.6184e+00, -1.0066e+01, -6.7929e+01,\n",
       "          5.0504e+01, -1.4959e+02, -3.7107e+01, -3.6962e+01,  2.5165e+01,\n",
       "          1.5717e+02,  8.4822e+00, -3.9669e+01,  8.1629e+01, -5.9214e+01,\n",
       "          1.4810e+01,  7.5851e+00, -2.1190e+02, -1.7189e+01,  1.0698e+02,\n",
       "          2.3015e+01, -2.0704e+01,  1.2337e+02, -5.7971e+01,  4.4582e+00],\n",
       "        [-5.0778e+01, -7.4182e-01, -3.7135e+01,  3.6605e+02, -5.7145e+00,\n",
       "         -3.4650e-01,  1.8894e+02, -5.6267e+01, -8.9250e+00, -2.7623e+00,\n",
       "         -3.7977e+01, -7.3947e+00,  4.3530e+01, -6.6719e+01, -2.8163e+02,\n",
       "          5.8093e+01, -5.0363e+01,  1.1635e+01, -7.6646e+01,  7.0693e+00,\n",
       "         -7.5766e+01, -1.9236e+02,  2.2575e+02, -1.8890e+00, -7.9903e+01,\n",
       "          2.3887e+01, -7.7867e+01, -1.6021e+01, -3.1259e+01,  9.3821e+01,\n",
       "          5.2822e-01, -1.2558e+02, -1.4052e+02, -6.0892e+01,  1.2331e+01,\n",
       "         -3.5102e+01,  3.1422e+01, -2.9365e+00, -1.2948e+02, -1.3205e+01,\n",
       "         -3.3355e+01,  1.7578e+02, -9.7432e+01, -1.1810e+00,  9.6353e+01,\n",
       "          8.3897e+01, -5.1150e+01,  5.2938e+01,  8.6894e+00,  9.2210e+01,\n",
       "         -9.4253e+01, -9.4298e+00, -3.5137e+01,  9.6806e+00,  1.4129e+02,\n",
       "         -1.4163e+01, -7.3406e+00,  3.5931e+01, -2.4163e+01, -3.4291e+01,\n",
       "          5.5937e+01,  2.2646e+01, -4.9363e+01,  1.1753e+02, -6.6994e+00,\n",
       "          2.1486e+01,  2.8363e+01, -6.4503e+01,  1.3484e+01, -3.7949e+01,\n",
       "          1.8237e+01,  1.9902e+02, -1.7252e+01, -6.0405e-01, -3.5023e+01,\n",
       "         -3.9571e+01, -6.1559e+00,  4.7006e+01,  1.0131e+02,  2.3032e+02,\n",
       "          5.7837e+01, -1.8862e+01, -8.4107e+01, -2.9870e+01, -1.9860e+00,\n",
       "         -3.9954e+01,  5.8156e+01, -6.8922e+01, -4.4219e+00, -5.6065e+01,\n",
       "         -2.6442e+02, -1.2251e+02, -2.6255e+02, -1.7522e+01,  1.1676e+01,\n",
       "          1.5043e+01, -2.1070e+01,  1.9190e+01, -7.0813e+02, -2.8127e+01],\n",
       "        [-2.5535e+01,  2.0265e+01, -6.7111e+00,  6.6088e+01, -5.5596e+00,\n",
       "         -6.2219e+01,  2.0301e+02,  9.0076e+01, -1.7478e+01,  3.3862e+01,\n",
       "          7.7134e+01,  3.3944e+01,  6.3991e+01,  2.3816e+01,  3.6220e+02,\n",
       "         -1.0129e+02,  2.4040e+01, -6.9800e+00, -2.4122e+01, -8.2320e+00,\n",
       "         -3.5083e+01, -9.6968e+01,  1.1179e+01,  1.6117e+02, -1.4863e+02,\n",
       "          3.0843e+02, -1.4114e+02,  3.2358e+01,  1.5118e+02, -1.0729e+01,\n",
       "          6.6430e+00,  1.3181e+02, -4.2576e+01, -4.3289e+00,  7.5739e+01,\n",
       "          1.0926e+02,  2.4085e+01, -9.0395e+01,  3.6458e+01, -6.1171e+01,\n",
       "         -1.6690e+00, -3.9484e+00,  6.3227e+01,  4.5796e+01,  3.3820e+01,\n",
       "          3.2077e+01, -8.3561e+00, -3.5004e+01, -1.5283e+00, -6.2018e+00,\n",
       "          1.0074e+02,  1.5344e+01, -1.3185e+01,  6.3865e+01,  2.2393e+01,\n",
       "         -7.2494e+00,  3.0037e+00, -7.9148e+01, -1.6653e+01,  6.8241e+01,\n",
       "         -3.1050e+00, -1.5560e+02, -8.2378e+00, -6.8988e+01, -9.3982e+00,\n",
       "          3.8884e+01,  1.6767e+02,  2.2579e+01, -1.0022e+01,  6.0288e+01,\n",
       "          7.4336e+01, -4.0114e+02, -2.1448e+01, -9.7468e+00,  7.7567e+00,\n",
       "          2.9926e+02, -9.7810e+00, -6.9960e+01, -2.9021e+01, -4.2611e+01,\n",
       "          2.5588e+00, -3.1714e+01,  3.2647e+01,  3.8914e+01, -1.4411e+01,\n",
       "         -8.6132e+00,  4.1886e+00,  3.5667e+01,  6.3555e+01, -1.0386e+02,\n",
       "         -2.4826e+01,  5.9633e+01,  1.2473e+02,  2.0734e+01, -2.0207e+02,\n",
       "          2.5957e+01,  2.7337e+01, -1.5676e+02,  2.6141e+02,  2.4360e+01],\n",
       "        [ 2.9210e+01, -3.6676e+01, -5.3098e+01,  7.6697e+01,  5.8587e+00,\n",
       "          1.3667e+02, -6.3358e+01,  8.0159e+01,  2.7155e+01, -4.3537e+01,\n",
       "         -9.7158e+01,  7.4936e+01, -1.4341e+01, -6.8773e+01,  2.1541e+02,\n",
       "         -5.0007e+01,  8.6279e+01,  1.2458e+01,  5.0964e+01, -9.3237e+01,\n",
       "         -4.9030e+01,  3.0045e+01, -1.0050e+02, -7.8866e+01, -4.0250e+01,\n",
       "          1.1714e+02,  6.5622e+01, -1.4546e+01,  2.1496e+02,  1.3880e+01,\n",
       "          3.4922e+01, -1.9270e+01, -1.4914e+01, -7.0882e+01, -4.8140e+01,\n",
       "          6.3804e+01, -2.8944e+01,  1.1510e+01,  4.7261e+01,  1.2079e+02,\n",
       "          1.0079e+01,  2.1557e+02,  1.0084e+02, -1.5562e+01, -2.6485e+01,\n",
       "          1.1308e+02,  2.3150e+02,  1.3660e+02, -2.9825e+01,  3.9079e+01,\n",
       "          3.9333e-01, -3.3042e+01,  7.4442e+00, -2.0862e+01, -3.3876e+01,\n",
       "         -4.4275e+00,  2.4363e+00,  1.0887e+02,  2.7500e+01, -1.5945e+02,\n",
       "         -2.1705e+01, -1.6578e+02, -5.8431e+01, -1.8203e+01,  1.1256e+01,\n",
       "          3.9262e+00, -1.2489e+02,  1.7529e+01, -8.3084e+01, -5.9436e+01,\n",
       "         -4.2896e+01, -1.5660e+02,  1.1945e+01, -7.8350e+01, -3.1100e+00,\n",
       "         -2.4119e+02, -5.9631e+01, -1.9558e+01,  4.3334e+01,  6.2011e-01,\n",
       "          9.2894e+01,  1.1710e+02,  2.3975e+01,  2.5923e+01,  1.3320e+01,\n",
       "          6.8645e+01, -8.2031e+00,  3.1945e+00,  5.5067e+01,  2.4994e+01,\n",
       "         -1.6263e+02, -6.4736e+01, -4.8295e+02, -2.0660e+01, -1.5519e+02,\n",
       "         -9.2851e+00, -2.7780e+01,  1.2126e+01, -4.1787e+02, -2.7977e+01],\n",
       "        [ 2.7863e+01,  2.2864e+01,  6.3849e+01, -9.9894e+01, -2.3058e+01,\n",
       "          5.5624e+00, -6.4720e+02, -4.8270e+01, -1.2479e+00,  7.3261e+01,\n",
       "         -6.7624e+01, -1.2569e+00, -5.2944e+00,  3.0946e+01, -1.0867e+02,\n",
       "         -1.2183e+01,  3.2934e+01,  3.9827e+01,  2.1948e+02, -6.1233e+01,\n",
       "          9.4816e+01, -2.7325e+02, -4.8528e+00, -1.4158e+02, -1.2698e+01,\n",
       "          4.5209e+01,  4.3736e+01, -2.5714e+00, -9.2553e+01, -5.2938e+01,\n",
       "         -2.6358e+00, -3.5126e+01,  1.1965e+02,  3.1748e+01,  2.9714e+01,\n",
       "          4.7223e+01, -1.8658e+01,  4.0158e+00, -2.0873e+01, -6.5914e+01,\n",
       "         -1.0635e+02, -7.1674e+01,  5.7714e+01, -4.8951e+01, -9.8687e+01,\n",
       "         -3.9815e+01, -3.0554e+01, -3.7988e+01, -7.4145e+01,  7.6452e+01,\n",
       "         -2.0404e+01,  2.0197e+01,  4.0731e+01, -5.1776e+01, -5.6612e+01,\n",
       "          1.1324e+01,  2.4573e+01, -2.9683e+00,  1.7808e+01,  1.0606e+02,\n",
       "         -2.0612e+01,  1.4390e+02,  1.1781e+01, -5.4597e+00, -7.8493e+01,\n",
       "         -4.8871e+01,  1.1273e+02, -1.4681e+01,  1.0980e+02, -3.6514e+01,\n",
       "          8.0194e+01, -3.1198e+02,  3.1567e+00,  8.5530e-01, -4.6745e+01,\n",
       "          1.0935e+02, -1.7095e+01, -3.5322e+01, -2.1161e+01, -5.0420e+01,\n",
       "         -4.2382e+01, -1.7545e+00,  2.2361e+01, -5.9894e+01, -4.0153e+01,\n",
       "         -1.3668e+02, -3.8899e+01, -1.3194e+01, -8.8683e+01,  1.6288e+02,\n",
       "         -8.2228e+01, -1.4837e+01,  5.6913e+01,  4.2480e+00,  1.5479e+02,\n",
       "         -9.1203e-01,  3.1805e+01, -3.3433e+01, -1.5193e+02,  1.4178e+01],\n",
       "        [ 3.1927e+01,  2.6076e+01,  6.0864e+01, -2.4906e+02,  5.3527e+01,\n",
       "         -1.4094e+02,  9.7482e+01, -2.4309e+01,  5.1093e+01, -2.8225e+01,\n",
       "         -1.4387e+02,  6.5206e+01, -1.2013e+02,  7.3158e+01, -2.0612e+02,\n",
       "          1.1763e+02, -5.2661e+01,  1.4611e+00, -6.2254e+01,  2.8061e+01,\n",
       "          8.2907e+01,  5.3934e+02, -7.3829e+00,  2.2726e+02,  2.4032e+02,\n",
       "         -3.9669e+02,  1.2650e+02,  6.1322e+01,  2.2581e+02, -2.2636e+01,\n",
       "         -7.2559e+01, -4.5642e+01, -9.1114e+01,  6.7632e+01, -5.5111e+01,\n",
       "         -1.5723e+02, -1.7334e+01,  7.5460e+01,  6.4072e+01, -1.6234e+00,\n",
       "          6.9578e+01, -1.2433e+01,  4.0621e+01,  2.3498e+01,  1.4240e+02,\n",
       "          1.1543e+01,  1.6394e+01,  1.0625e+02,  1.8354e+02,  7.2195e+01,\n",
       "          1.1633e+01,  1.2836e+02, -3.6649e+01,  8.4071e+01, -1.3009e+02,\n",
       "          5.0896e+01,  1.5211e+01,  7.4114e+01,  5.9386e+01, -4.0883e+01,\n",
       "         -3.6431e+01,  7.7065e+02,  7.1953e+01,  3.3199e+01,  4.0194e+01,\n",
       "         -2.6461e+01,  1.0480e+02,  3.2594e+00, -1.2233e+00,  1.1319e+02,\n",
       "         -4.2702e+02,  1.9134e+02,  5.6362e+01,  9.1620e+01,  5.8367e+01,\n",
       "          5.2028e+01,  1.3382e+00,  3.3395e+01, -3.7561e+01,  1.4877e+02,\n",
       "         -7.9048e+01,  2.7080e+02,  5.7581e+01,  1.0284e+02, -6.8330e+01,\n",
       "          6.9865e+01,  8.4434e+00, -1.0466e+02,  9.9882e+01, -8.1678e+01,\n",
       "          2.2209e+02,  1.0428e+02, -3.4601e+02,  4.5327e+01,  2.3558e+02,\n",
       "         -1.7105e+01,  2.7033e+01, -8.7805e+00,  4.0410e+02,  2.5414e+00],\n",
       "        [-4.6857e+01,  1.1070e+01, -5.4472e+01,  1.4139e+02, -5.8597e-01,\n",
       "          6.2197e+01,  4.0382e+01,  5.2502e+01, -4.0948e+01,  1.0061e+01,\n",
       "          3.7299e+01, -6.8863e+01,  1.3843e+01, -4.0720e+01,  7.2646e+01,\n",
       "          1.5460e+01, -2.6373e+00, -1.5407e+01, -1.8616e+02,  3.3165e+01,\n",
       "          1.1206e+01, -1.1937e+02, -5.2528e+01, -7.8909e+01,  4.9762e+00,\n",
       "         -1.2550e+02, -6.1169e+01, -3.9397e+01, -2.2690e+02, -5.5673e+00,\n",
       "         -8.7850e+00, -5.7457e+01,  1.2443e+02, -2.0237e+01, -2.8859e+01,\n",
       "          1.9810e+01, -1.7775e+00, -3.4580e+01,  6.5421e+00,  9.8773e+01,\n",
       "         -1.4179e+01, -1.9605e+02, -1.2847e+02,  1.6437e+01, -1.2075e+01,\n",
       "         -1.6837e+02, -5.3302e+01, -2.1411e+01, -1.1955e+01, -7.8119e+01,\n",
       "          4.8964e+01,  8.1824e+01, -1.6698e+01,  5.5346e+01, -6.2077e+01,\n",
       "         -1.4223e+01, -6.1207e+01,  6.6723e+01, -3.1369e+01,  3.3526e+01,\n",
       "          1.2336e+01, -5.3795e+02, -5.0964e+01,  8.3360e+00,  1.1107e+01,\n",
       "          1.8716e+01, -7.1307e+01, -1.9298e+01,  3.9718e+01,  1.0255e+01,\n",
       "          2.2503e+02, -1.1416e+01, -5.5747e+01,  1.4390e+01, -1.1392e+01,\n",
       "         -1.0184e+02,  1.5086e+01,  3.8071e+01, -1.6810e+01, -6.2215e+01,\n",
       "          6.2608e+01, -2.1135e+02, -3.0761e+01,  3.6153e+01,  6.7828e+01,\n",
       "          2.7767e+01,  3.2499e+01, -5.8890e+01,  4.2295e+01,  7.9086e+01,\n",
       "          7.4040e+01, -3.2243e+01,  2.9001e+02, -3.7268e+01, -2.7624e+02,\n",
       "          3.1283e+01, -2.1365e+01, -5.7023e+01, -5.5668e+01,  7.8170e+01],\n",
       "        [ 2.2808e+00,  4.6552e+00,  3.4368e+01, -2.0481e+02, -7.3324e+01,\n",
       "          9.8368e+01,  1.4756e+02,  5.5407e+01, -3.5252e+01, -2.5871e+01,\n",
       "          3.5976e+01,  2.0728e+00, -3.4548e+00,  2.5057e+00,  3.3191e+01,\n",
       "         -1.3553e+02,  1.1704e+02, -4.9714e+01, -1.0146e+02, -5.3299e+01,\n",
       "         -1.5616e+02, -3.4880e+01, -1.0439e+02,  2.6254e+02, -5.5023e+01,\n",
       "          1.3303e+02, -1.2960e+02,  2.4157e+01,  4.8199e+01, -7.9351e+01,\n",
       "         -4.3561e+01,  9.0925e+01, -1.1250e+01,  5.0253e+01,  7.8743e+00,\n",
       "         -3.8587e+01, -9.6752e+00,  3.2989e+01,  4.1991e+01,  1.9351e+01,\n",
       "          6.5633e+00,  3.8339e+01, -3.9143e+01, -3.1659e+01,  6.8063e+01,\n",
       "          1.0766e+02,  1.5266e+02, -5.7241e+01, -2.3694e+00,  1.8003e+01,\n",
       "         -4.4906e+01,  1.9024e+01, -1.3860e+01, -8.1581e+01, -2.6465e+01,\n",
       "         -8.7480e+00,  6.5163e+00, -1.3824e+02, -3.2847e+01,  1.1753e+02,\n",
       "         -3.0555e+01,  1.2480e+02,  5.6736e+01, -1.1484e+02,  2.5270e+01,\n",
       "          2.3392e+00, -1.3622e+02,  6.0843e+01,  2.7669e+01,  3.8941e+01,\n",
       "         -6.1347e+01,  3.2650e+02, -3.0078e+01,  9.7084e+00, -8.2675e+01,\n",
       "          8.5100e+01, -6.2265e+01,  1.6565e+00, -1.5335e+01, -4.8959e+01,\n",
       "         -1.1466e+02,  2.3275e+01,  3.8761e+01, -5.4039e+01,  2.0668e+01,\n",
       "         -1.6236e+02, -2.6817e+01,  4.1949e+01, -1.5556e+02, -6.3575e+01,\n",
       "          1.2246e+02, -2.3412e+01,  3.9641e+02, -4.9961e+01,  6.3982e+01,\n",
       "         -2.6826e+01,  3.3763e+01, -6.4339e+01,  6.2861e+02, -6.4338e+01]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-microwave",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
