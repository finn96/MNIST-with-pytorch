{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seasonal-suggestion",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "The first step of this walkthrough is getting our hands on the data that will train and test our PyTorch model. The data is available from a number of sources, including websites like [kaggle](https://www.kaggle.com/c/digit-recognizer/data) and [Louisiana State University's website](https://csc.lsu.edu/~saikat/n-mnist/). It's even made available directly through [torchvision](https://pytorch.org/vision/0.8/datasets.html#mnist).\n",
    "\n",
    "We are going to go right to the source on this one, and download it directly from [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/). The dataset has become quite widely used in the world of image classification, and it was popularized after Yann's 1998 Paper [Gradient-based learning applied to document recognition]\n",
    "(https://ieeexplore.ieee.org/document/726791).\n",
    "\n",
    "\n",
    "!TODO! Describe dataset\n",
    "## Data Sources (word?)\n",
    "There are 4 files we need to train our network:\n",
    "- The set of training images:  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "- The set of training labels:  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "- The set of testing images:   http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "- The set of testing labels:   http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "To download them, I recommend simply (from the root level of this repository):\n",
    "```\n",
    "$> mkdir data\n",
    "$> wget --directory-prefix data http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "$> wget --directory-prefix data http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "$> wget --directory-prefix data http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "$> wget --directory-prefix data http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "```\n",
    "\n",
    "The files are gunzipped, so we'll need to uncompress them. We can do so in one line:\n",
    "```\n",
    "$> gunzip data/*\n",
    "```\n",
    "\n",
    "Now we have all the data we need on our local machine. Let's start out by taking a look at the data and figuring out how to parse it.\n",
    "\n",
    "## Data Parsing and Loading\n",
    "\n",
    "*Aside: Many of you may wonder: why go through all the trouble of parsing the dataset when it is so easily available in nicer formats from other sources. (As mentioned before, `torchvision` has this dataset built in and ready to be used with a `TrainLoader`.) There's even a python library called `python-mnist` that can automatically parse these files for you. I chose to include this portion of the walkthrough because I myself found it of great educational value to learn how to parse the data from raw, unsigned bytes. In the real world of machine learning, your source data is going to start off messy. It's not going to be already built in to your ML framework where you can download it and create a fancy training iterator with a single function call. I believe that learning to parse the data yourself is good practice for when it comes time to use machine learning in your own projects, on your own data, and in pursuit of your interests.*\n",
    "\n",
    "The data is stored as bytes. A schema is provided on the website for the byte ordering:\n",
    "- Labels file:\n",
    "    - **Bytes \\[0,4):** Magic Number (MSB)\n",
    "    - **Bytes \\[4,8):** 32 bit signed integer representing the number of labels\n",
    "    - **Bytes \\[8,):**  The image labels. Each unsigned byte is a label.\n",
    "\n",
    "- Images file:\n",
    "    - **Bytes \\[0,4):** Magic Number (MSB)\n",
    "    - **Bytes \\[4,8):** 32 bit signed integer representing the number of images\n",
    "    - **Bytes \\[8,12):** 32 bit signed integer representing the number of rows per image\n",
    "    - **Bytes \\[12,16):** 32 bit signed integer represneting the number of columns per image\n",
    "    - **Bytes \\[15,):** The pixels. Each is an unsigned byte with a value between 0 and 255.\n",
    "\n",
    "#### We can start by parsing the labels file. It has a slighly simpler schema than the images file, so it will get us used to reading files as raw bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caroline-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the labels file\n",
    "labels = []\n",
    "with open(\"./data/train-labels-idx1-ubyte\", 'rb') as label_file:\n",
    "    label_file.seek(4)  # Skip past the magic number\n",
    "    num_labels = int.from_bytes(label_file.read(4), 'big')  # Read and parse uint32 that holds the number of labels\n",
    "    \n",
    "    # Iterate through the remainder of the file\n",
    "    for _ in range(num_labels):\n",
    "        labels.append(int.from_bytes(label_file.read(1), 'big'))  # Read a byte, parse an integer from it, and store it.\n",
    "    \n",
    "    # Check that we've reached the end of the file\n",
    "    assert label_file.tell() == label_file.seek(0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-diagram",
   "metadata": {},
   "source": [
    "We should run a few checks to make sure that we parsed everything correctly. Here's what we can check\n",
    "- The number of labels we parsed is equal to the number stored in bytes \\[4,7) of the file\n",
    "- Every label should be in the [0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "functional-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(labels) == num_labels\n",
    "assert any(label not in range(0,10) for label in labels) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-table",
   "metadata": {},
   "source": [
    "#### Alright. We've got the labels. Time to move on to the images.\n",
    "\n",
    "This file is going to be a little harder to parse, but all we have to do is think about what data makes up an \"image\". An image is a made up of pixels, and those pixels are arranged in 2d space with a given height and a given width. In the case of grayscale images, like the ones we're using, the value of those pixels is represented by a single number. Thinking about this for a little bit, we can come up with psuedo-code showing how we would read a single image of known dimensions:\n",
    "\n",
    "```\n",
    "image_file = read(image_file)\n",
    "image_data = list(list())  # 2d list\n",
    "for r in [0,number_of_rows):\n",
    "    for c in [0,numer_of_cols):\n",
    "        pixel = image_fule.readbyte()\n",
    "        image_data[r][c] = pixel\n",
    "```\n",
    "\n",
    "In order to read multiple images, all we have to do is add one more for loop.\n",
    "\n",
    "Let's read in the images. Because python, the actual code doesn't look too much different from the psudeo code.\n",
    "\n",
    "| !TODO! Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "beginning-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train-images-idx3-ubyte\", 'rb') as image_file:\n",
    "    image_file.seek(4)  # Skip past magic number\n",
    "    num_images = int.from_bytes(image_file.read(4), \"big\")  # uint32 telling us the number of images\n",
    "    num_rows = int.from_bytes(image_file.read(4), \"big\")    # uint32 telling us the number of rows per image\n",
    "    num_cols = int.from_bytes(image_file.read(4), \"big\")    # uint32 telling us the number of columns per image\n",
    "    images = []\n",
    "    \n",
    "    # Iterate through the pixels and group them accordingly.\n",
    "    for _ in range(num_images):\n",
    "        image = []\n",
    "        for _ in range(num_rows):\n",
    "            col = list(image_file.read(num_cols))\n",
    "            image.append(col)          \n",
    "        images.append(image)\n",
    "\n",
    "# Note that np.reshape(np.array(list(images_file.read(num_rows * num_columns))), (num_images, num_rows, num_columns) is an easy one liner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-quantity",
   "metadata": {},
   "source": [
    "Again, we can run a few checks to make sure that we parsed everything correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "tired-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(images) == num_images\n",
    "assert len(images[0]) == num_rows\n",
    "assert len(images[0][0]) == num_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-meeting",
   "metadata": {},
   "source": [
    "#### Finally, we can print out a few of our images and their associated labels to make sure we got everything right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "positive-dispute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i1, i2, i3 = np.random.randint(0, num_images, 3)   # Three randomly chosen images\n",
    "l1, l2, l3 = labels[i1], labels[i2], labels[i3]    # Get the associated labels for the chosen images\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "fig.add_subplot(1,4,1)\n",
    "plt.imshow(images[i1], cmap='gray')\n",
    "plt.text(9, 35, f\"Label: {l1}\")\n",
    "\n",
    "fig.add_subplot(1,4,2)\n",
    "plt.imshow(images[i2], cmap='gray')\n",
    "plt.text(10,35, f\"Label: {l2}\")\n",
    "\n",
    "fig.add_subplot(1,4,3)\n",
    "plt.imshow(images[i3], cmap='gray')\n",
    "plt.text(11,35, f\"Label: {l3}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-delhi",
   "metadata": {},
   "source": [
    "And there we have it, we've successfully parsed our training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-poland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
